# Towards A Rigorous Science of Interpretable Machine Learning
- 可解释性评估的两个方面：系统在实际应用程序或其简化版本中有用，那么它必须以某种方式可解释；量化代理评估可解释性：首先声称某些模型分类为 可以解释，然后提出在该类中进行优化的算法。
- 问题：可解释的模型类别内不一定所有的模型都可以解释
- 可解释的分类：以人为基础和以功能为基础的评估
- 可解释与机器学习其他标准的关系：可以辅助确认其他标准（可靠性，公平性，鲁棒性）是否达到
- 无需可解释的场景：对不可接受的结果没有重大影响；即使系统不完善，由于问题以及应用成熟使得我们对于决策结果充分信任
- 需求可解释的原因：问题的不完整性，比如小数据集以及有限的特征
- 具体例子：隐私性，非歧视（标准的模糊），多目标互相冲突
- 可解释的主要目的：使得问题能够充分的暴露出来